---
title: 容器网络原理
date: 2021-06-10
categories: [Docker和容器]
tags: [docker,Go]
---

## 概览

- bridge 虚拟网桥模式
- host 宿主机共享模式
- none 无网络模式
- container 容器共享模式

​     

## bridge网桥模式

docker网络使用Linux提供的`veth pair`和`virtual bridge`技术来实现网桥模式

在该模式下每个容器都有一个独立的局域网虚拟IP，通讯范围如下:

- 跨网段的两个容器即使是在同一台宿主机上也不可以互通 （为什么？）
- 容器和宿主机可以互通
- 容器可以连接外界网络，外界网络连接容器的服务需要进行端口映射

创建虚拟网桥

```bash
docker network create -d bridge --subnet 192.168.25.0/24 --gateway 192.168.25.1 mynetwork
```

创建容器，指定网络

```bash
docker run -d --name pingip --net mynetwork biningo/pingip
```

如果想让外网访问容器的服务，可以指定端口映射，这样外网直接访问宿主机的端口就可以访问容器的服务了

```bash
docker run -d --name pingip --net mynetwork -p 8080:9090 biningo/pingip
```

`docker-proxy`进程负责进行内网穿透，物理网卡上对应映射端口的流量会转发到docker-proxy进程上，然后docker-proxy再转发到容器内，容器内响应数据包也见过docker-proxy进行转发到物理网卡对应的端口中

如果容器想要访问外网则必须进过`iptables`的NAT网络地址转换才可以访问外网

> 在自定义的网络中是可以直接通过容器名进行访问的，而在docker0网络下则只能通过IP进行访问同网段的主机

​    

## host宿主机共享模式

```bash
docker run --name busybox -it --net host   busybox:1.32.0 sh
```

进入容器执行`ifconfig`命令可以看到和宿主机上的网络一模一样，容器没有自己的IP，外界直接访问宿主机即可访问容器的服务

​    

## none无网络模式

```bash
docker run --name busybox -it --net none   busybox:1.32.0 sh
```

进入容器执行`ifconfig`命令可以看到只有一个`lo`环回测试地址的网络接口，只允许容器访问自己，外界都不可访问

none网络主要是为了保障容器的内部安全，直接让外界无法访问容器，应用与一些安全性较高的场景

​    

## container容器共享网络模式

一个容器可以共享另外一个容器的网络，网络主容器被删除了，那么其他从容器就没有网络了

下面创建有自己IP的主容器

```bash
docker run --name busybox1 -it  busybox:1.32.0 sh
```

下面创建2个从容器，共享主容器的网络

```bash
docker run --name busybox2 -it --net container:busybox1 busybox:1.32.0 sh
docker run --name busybox3 -it --net container:busybox1 busybox:1.32.0 sh
```

此时这三个容器都是同一个IP，同一个`veth pair`，同一个虚拟网桥。共享网络的容器不能占用相同的端口

​    

## Linux Veth Pair

`veth pair`是一对网络接口，一头发送数据即转发到另外一头，类似于两台机器之间的网线，作用是用于两个隔离的`Network Namespace`之间进行网络通讯

查看所有的`Network Namespace`

```bash
ip netns ls
```

创建两个network namespace

```bash
ip netns add ns1
ip netns add ns2
```

创建一对veth虚拟网卡(veth0,veth1)，注意一定是成对出现的

```bash
ip link add veth0 type veth peer name veth1
```

将veth0、veth1分别移动到ns1、ns2中

```bash
ip link set veth0 netns ns1
ip link set veth1 netns ns2
```

给设备分配ip地址，并且使其生效

> 注意veth pair两个网卡必须处于同一个网段，如果不同一个网段需要走路由，则无法ping通

```bash
ip netns exec ns1 ifconfig veth0 172.18.0.2/24 up
ip netns exec ns2 ifconfig veth1 172.18.0.3/24 up

#也可以都使用ip命令
ip addr add 172.18.0.2/24 dev eth0
ip link set eth0 up
```

查看ns1、ns2中的网络设备

```bash
ip netns exec ns1 ifconfig
ip netns exec ns1 ip link

ip netns exec ns2 ifconfig
ip netns exec ns2 ip link
```

修改网卡的名字

```bash
ip netns exec ns1 ip link set veth0 name eth0
ip netns exec ns2 ip link set veth1 name eth0
```

进行ping查看连通性，两个namespace之间就可以连通了

```bash
ip netns exec ns1 ping 172.18.0.3
ip netns exec ns2 ping 172.18.0.2
```

​    

## Linux Virtual Bridge

Linux还支持创建虚拟的bridge，可以看成是一台虚拟的交换机，可以中转多个namespace之间的流量，只需要veth pair的一头挂载到bridge上即可实现流量转发

bridge接受到数据包之后会先给所有的端口都发送ARP请求获取到IP地址对应的mac地址，然后再将数据包转发给对应mac地址的veth口，然后就到达目标了

bridge和真实世界的交换机一样具有学习功能，会记录mac地址对应了那个veth口，veth就相当于真实世界的网线接口，下次bridge再收到数据包时则直接转发到对应的arp口也就是连接在bridge的veth的一端，进而转发到目标namespace中

> **注意，网络设备一旦挂载到bridge中其IP地址就失效了，挂载在bridge中的veth并不需要IP地址**

```bash
#1.添加bridge
brctl addbr br0
brctl show

#2.增加3个命名空间
ip netns add ns1
ip netns add ns2
ip netns add ns3
ip netns ls

#3.创建3个veth pair
ip link add veth1 type veth peer name br0-veth1
ip link add veth2 type veth peer name br0-veth2
ip link add veth3 type veth peer name br0-veth3
ip link

#4.将veth加入各自的namespace
ip link set veth1 netns ns1
ip link set veth2 netns ns2
ip link set veth3 netns ns3

#5.挂载veth到br0
brctl addif br0 br0-veth1
brctl addif br0 br0-veth2
brctl addif br0 br0-veth3

#6.设置ip并启用
ip netns exec ns1 ifconfig veth1 172.25.0.11/24 up
ip netns exec ns2 ifconfig veth2 172.25.0.12/24 up
ip netns exec ns3 ifconfig veth3 172.25.0.13/24 up
ifconfig br0 172.25.0.1/24 up
ip link set br0-veth1 up
ip link set br0-veth2 up
ip link set br0-veth3 up

#查看
ip netns exec ns1 ip link
ip netns exec ns2 ip link
ip netns exec ns3 ip link

#7.测试连通性 3个ns之间可以通过IP互通
ip netns exec ns1 ping 172.25.0.12
ip netns exec ns1 ping 172.25.0.13
ip netns exec ns2 ping 172.25.0.11
ip netns exec ns2 ping 172.25.0.13
ip netns exec ns3 ping 172.25.0.11
ip netns exec ns3 ping 172.25.0.12
```

给宿主机添加route，实现宿主机到容器的访问

> **注意，br0虚拟网桥必须分配一个IP地址，否则无法和宿主机互通，br0虚拟网桥相当于宿主机上的一个设备，如果没有IP则无法连通**

```bash
route add -net 172.25.0.0/24 dev br0
ping 172.25.0.11
```

给容器内部添加默认route，实现容器到宿主机的访问

```bash
sudo ip netns exec ns1 route add default dev veth1
sudo ip netns exec ns1 ping 192.168.43.21
```

多个网桥之间互通也是可以的，只需要在容器内部设置默认路由，并且给网桥一个IP地址即可，那么这个虚拟网桥不仅仅就充当集线器的作用了，还充当了网关的作用。虚拟网桥根据其所在的namespace空间上route信息然后转发到对应的设备上

如果需要让容器访问互联网则需要借助`iptables`机制，将br0网桥转发出来的外网流量nat为宿主机的地址再转发到外网，因为我们私有地址访问外网会被外网的路由器给丢弃，必须nat为网关的地址才可以访问外网

如果外网需要访问容器内部的服务则需要作**端口映射**，将容器内部的端口和宿主机端口映射起来，这样访问宿主机中的对应的端口就会被转发到容器对应的端口中，容器的响应也会被重新转化为宿主机对应的端口再转发出来

​      

## 跨网段两个namespace如何通讯

两个跨网段通讯的namespace之间需要添加各自的route条目才可以通讯，如果只添加一边的route条目则响应包就无法响应回来了

```bash
ip netns add ns1
ip netns add ns2

ip link add veth0-1 type veth peer name veth0-2
ip link set veth0-1 netns ns1
ip link set veth0-2 netns ns2
ip netns exec ns1 ifconfig veth0-1 192.168.20.11/24 up
ip netns exec ns2 ifconfig veth0-2 192.168.21.11/24 up

#分别配上路由条目 让请求包和响应包都能够到达对方
#这里配上默认路由也可
ip netns exec ns1 route add  -net 192.168.21.0/24 dev veth0-1
ip netns exec ns2 route add  -net 192.168.20.0/24 dev veth0-2

#测试
ip netns exec ns1 ping 192.168.21.11
ip netns exec ns2 ping 192.168.20.11
```

通讯过程如下:

- 在`ns1`中ping IP时会查找ns1中的route，然后根据规则将数据包转发出去，一般在ns包配置的路由都从veth0-1发送出去
- 从`veth0-1`发送出去之后就立即到达了另外一端`veth0-2`，此时数据就传递到了`ns2`中，此时veth0-2会将数据包传递到内核网络协议栈
- 内核网络协议栈返回响应包之后也会立即查询`ns2`中的route表项，匹配上则立即通过虚拟设备转发出去，一般都会将默认路由的出口设置为veth网卡，如果路由匹配不上则响应包就无法传递到对方

上述过程也解释了为什么同网段默认就可以进行通讯，而如果两个`veth pair`分配了不同网段的IP则需要给双方的namespace中都设置一条路由，让数据包可以互相转发

> 如果不加入虚拟网桥的话则两个namespace则无法和宿主机通讯，只能两个namespace互相通讯

​     

## 为什么Docker多个网段不通

Docker提供了bridge模式来实现同网段下的多个容器连通、容器和宿主机、容器和外界，但是在Docker中跨网段连接是不被允许的，按照上面的实验跨网桥其实是可以通过Linux的`ip_forward`特性来进行通讯的（同一台宿主机之间多个网卡可以互相通讯），但是为什么Docker却不能跨网段通讯呢？这是因为Docker设置了`iptables`规则来禁止多个虚拟网桥之间通讯

​    

## 容器如何访问外网

`iptables`进行SNAT

> **为什么我的namespace里无法访问DNS，但是Docker里却可以？？？**

​     

## 外网如何访问容器

`iptables`进行DNAT，将宿主机的端口和容器的端口进行映射

​    

## 巨人肩膀

[Docker容器学习梳理--容器间网络通信设置](https://www.huaweicloud.com/articles/9933f12e2049a03b02d1b4791e2b3f39.html)

[《跟唐老师学习云网络》 - Veth网线](https://bbs.huaweicloud.com/blogs/149798)

[《跟唐老师学云网络》—— 目录](https://bbs.huaweicloud.com/blogs/109721)

[理解 Linux 网络命名空间](https://www.qikqiak.com/post/learn-linux-net-namespace/)

[通过实验学习 Linux VETH 和 Bridge](https://gobomb.github.io/post/learning-linux-veth-and-bridge/)

[Linux云网络基础之虚拟网络设备 veth-pair 详解](https://ctimbai.github.io/2019/03/03/tech/net/vnet/veth-pair%E8%AF%A6%E8%A7%A3/)

[Docker 网络基础 | 虚拟网络设备对（veth）原理](https://cloud.tencent.com/developer/article/1835299)

[Introduction to Linux interfaces for virtual networking](https://developers.redhat.com/blog/2018/10/22/introduction-to-linux-interfaces-for-virtual-networking#)

[被 Linux Bridge Networking 的工作原理困扰了](https://www.v2ex.com/t/647239)

[Linux虚拟网络设备之bridge(桥)](https://segmentfault.com/a/1190000009491002)

