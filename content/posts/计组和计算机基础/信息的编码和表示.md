---
title: 信息的编码和表示
date: 2021-02-01
categories: [计组和计算机基础]
tags: [基础]
---

## 二进制算术运算

二进制的 **加减乘除** 运算和十进制相似，只不过二进制到`2`就需要进位，而十进制到`10`才需要进位而已，其他进制也都类似

CPU逻辑运算：`& | ^(异或) ~(取反)`  （由相应的与非门等电路组合而成）

CPU算术运算： **加法、位移** （通过上面的逻辑运算实现）

二进制的加减乘除都是通过 **加法、位移** 组合来实现的，CPU里面实现二进制的算术运算由相应的部件来实现

- **加法器（全加器）**  实现加法
- **除法器、乘法器** 实现乘除

### 1、二进制加减

二进制加法：`01+01=10` 第一位`1+1=0`然后需要进位并且需要链式进位，这和十进制一样，加法器基本原理就是

- **异或**（不带进位的加法`1+1=0  0+0=0`）
- **与** （计算进位,只有`1|1==1`才会产生进位）如果有进位还必须保存进位参与下一次运算

二进制里面的减法是通过加法来运算的，**减去一个数其实就是加上这个数的负数**，计算机为了表示负数，会出现很多问题，**原码、反码、补码**就是为了解决负数问题的（稍后讨论）

二进制加法规则：`0+0=0  1+0=1 1+1=1`

二进制减法规则：`0-0=0 1-0=1 0-1=1(需要向前借位) 1-1=0`

可以看到和十进制一样，只不过十进制有10种状态`0-9`而二进制只有`0-1`两种状态

弄清楚二进制运算只需要转变以前10进制运算观念即可

### 2、二进制乘除

二进制乘法比十进制还简单，运算规则和十进制一样，下面截取**《编码》**里的一张图片说明：

![](https://raw.githubusercontent.com/biningo/cdn/master/img/image-20201024231411557.png)

第一排`1101`叫被**被乘数**，第二排`1011`叫**乘数**

为了更直观感受，将每次乘下来的结果空白部分都补0：

```bash
00001101
00011010
00000000
01101000
--------
10001111
```

CPU乘法器：有`3`个寄存器组成：

- `A`：保存被乘数
- `B`：保存乘数
- `C`：保存结果

下面展示完整流程（假设在8位机器上）：

A：`00001101` B：`00001011` C：`00000000`

- `1*00001101=00001101`=> A：`00011010` B：`00000101` C：`00001101`
- `1*00011010=00011010`=> A：`00110100` B：`00000010` C：`00001101`
- `0*00110100=00000000`=> A：`01101000` B：`00000001` C：`01101000`
- `1*01101000=01101000`=> A：`11010000` B：`00000000`C：`10001111`

所以最终结果就是 `10001111`

除法也和十进制的 **竖式除法** 规则一致，但是底层实现还是比较复杂，我没弄懂QAQ

### 3、总结

加法：加法

减法：取反，加法

乘法：移位，逻辑判断，累加

除法：移位，逻辑判断，累减

其实不必要太纠结底层，以前有段时间我也一直纠结底层，甚至陷入一个无底洞，后面明白了，其实我们只要知道有这么个东西就行了，只要知道CPU里面有这么个东西能实现二进制的加减乘除就行了，其他都不需要我们关心

​    

## 为什么会有16进制

- 数据表示更加简短易读
- 一种计算机底层数制

计算机底层都只会识别`01`二进制，而出现`16进制`就是为了 **方便表示** ，比如一个`64`位系统，地址长度是`64`位的，那么就需要用64个01才能写出一个地址，而使用16进制则只需要`4`位即可表示，这样即简短又容易看懂

​    

## 整数的表示：原码、反码、补码

### 1、原码

计算机为了表示负数，必须牺牲最高位用来表示正负，比如一个`8位`的`int`：

- 如果是没有符号的，那么就有`8`位可以表示数字，所以范围就是`0-255`
- 如果是有符号的，那么最高位就要拿来充当符号位，所以只有`7`位用来表示数字了，范围就缩小了一半：`-127~127` 但是能表示正负了

这就是 **原码**  原码就是为了将正负表示出来，但是原码有如下几个缺陷：

- `0`有两个【10000000】【00000000】，表示的数值少了一个
- 运算不能得出正确结果：【 0001(`1`)+1001(`-1`)=1010 (`-2`) 】正确答案应该为：`0`
- 进行负数运算不方便

### 2、反码

> 解决了原码的正负数运算问题

为了能够方便的进行正负数运算同时运算不会出错，于是我们将原码进行了一些变化 **符号位不变，数据位相反** （至于为什么要这样其实不用纠结，就是这样QAQ）

【 0110(`1`)+1110(`-1`)=0000  】==> 1+(-1)=0

于是就解决了原码的正负运算问题，这就是**反码**

![](https://raw.githubusercontent.com/biningo/cdn/master/img/891e6b746e9ef18adafc1f478c570326_1440w.png)

反码也有缺点：**0有两种表示方法【0000】【1111】，所能表示的数值少了一个**

### 3、补码

为了解决两个0的情况，为了把`1111`这个0去掉，在反码基础上+1

那么1111（反码的`-0`）就会变成`10000`但是这里讨论的只是`4位`，所以`10000`截断之后就是`0000`

**注意：正数都是不变的，和原码一毛一样** 

这就叫： **补码**

![](https://raw.githubusercontent.com/biningo/cdn/master/img/d3617d2ceb02f6129c9b41361804cbe2_1440w.png)

可以看到，上面**正数部分都一样**，负数部分由于原码和反码都有两个0，所以他们表示的范围就是`-7~7` 如果`0`不看的话，正负数个数一样

而补码由于在反码的基础整体往上移动了一格去掉了一个反码的`1111`，下面空了一格，于是就多补了一个`-8`，范围就是`-8~7` `0`看作正数，正负数的个数还是一样

扩大到`8`位的补码表示的整数范围就是`-128~127`（原码是`-127~127`）

​    

## 定点数和浮点数

TODO

## 字符的表示

### ASCII码

`ASCII`编码每个符号采用`8`位来表示，占用**一个字节**，所以最多能表示`2^8=256`种符号，而`ASCII`编码只适用了后面的`7`位，一共有`128`个字符，最高位补0

 **ASCII主要适用于英语国家的信息表示，英语符号用ASCII表示已经足够了，对于希腊语汉语等复杂语言则无法表示**

![](https://raw.githubusercontent.com/biningo/cdn/master/img/ascii.jpg)

> 一般整数等数值型数据最好不要用字符串来存储，比如一个`32`位整数，用整数来存储最大只需要 `4byte` 而如果改用字符串`ASCII`码来存储，则需要`32byte`
>
> **这也是为什么我们在网络传输的时候需要二进制序列化来传输数据，而不是通过JSON、CSV格式** 这也是JSON的缺点

### Unicode

`Unicode`是一种全球统一的符号集合:

- 包括了全球至今为止的所有符号
- 每个符号的长度不一样，越后面越长
- 每个符号都有独一无二的二进制编码

| 范围                                | 含义                                                      |
| ----------------------------------- | --------------------------------------------------------- |
| U+0000(0x0000)~U+FFFF(0xFFFF)       | **基本平面(BMP)**，最先定义的一批字符集，包含最常用的字符 |
| U+10000(0x10000)~U+01FFFF(0x01FFFF) | **辅助平面(SMP)**，用于存放剩下的字符集                   |

可以看到前面的只需要`1byte、2byte`就够了，而越到后面的字符占用的字节越大，比如最后Unicode采用`3byte、4byte`表示一个字符，还包括一些标签符号

由于不同的字符占用的编码大小都是不一样的，前面字符占用小后面占用大，计算机就分不清到底是3byte表示一个字符还是2byte表示一个一个字符，我们可以将所有的字符都统一到最大的大小，也就是说即使是2byte的字符也必须用3byte来存储，但是这样就造成了空间的极大浪费，于是就出现了很多 **编码方式**：`UTF-8\16\32`、`GBK`等，这些编码方式就是为了解决 **Unicode字符长度不一样，计算机无法识别问题**

> **所以，Unicode只是一个字符集，只是规定了每种符号的二进制编码**

### UTF-8

是`Unicode`字符集的实现方式之一，最普遍的方式，是一种 **变长编码**，可以使用`1byte~4byte`表示不同长度的符号，比如英文ASCII码等用1byte，汉字用3byte，这样就大大的节省了空间，`ASCII` 也不用保存为和汉字一样长度了，只需要保存1byte，而且汉字也可以编码

UTF8编码规则如下

- 对于单字节的符号，字节的第一位设为`0`，**后面7位为这个符号的 Unicode 码**。因此**对于英语字母，UTF-8 编码和 ASCII 码是相同的**

- 对于`n`字节的符号（`n > 1`），第一个字节的前`n`位都设为`1`，第`n + 1`位设为`0`

    后面字节的前两位一律设为`10`。剩下的没有提及的二进制位，全部为这个符号的 Unicode 码

| Unicode 十六进制码点范围 | UTF-8 二进制                                 |
| ------------------------ | -------------------------------------------- |
| 0000 0000 - 0000 007F    | 0xxxxxxx（ASCII码）                          |
| 0000 0080 - 0000 07FF    | 110xxxxx 10xxxxxx（2字节的字符）             |
| 0000 0800 - 0000 FFFF    | 1110xxxx 10xxxxxx 10xxxxxx（3字节）          |
| 0001 0000 - 0010 FFFF    | 11110xxx 10xxxxxx 10xxxxxx 10xxxxxx（4字节） |

这样即可以轻松的根据规则来识别到底是1byte表示一个字符还是3byte表示一个字符了

​    

## 大小端

因为内存是以字节为编址的，但是很多数据类型都会占用多个字节，比如`int`类型占4字节，所以就会有两种排列方式，比如一个`int`类型的数`0x10000002`：

- 高地址放高位，低地址放低位：`0x02` ,`0x00`,`0x00`,`0x01`  这种就叫做**小端模式**
- 低地址放高位，高地址放低位：`0x01`,`0x00`,`0x00`,`0x02` 这种就叫做 **大端模式**

看一看到，大端模式是符合人类阅读习惯的，而小端模式是反的。他们的优缺点如下：

**小端模式优点：**

1. 内存的低地址处存放低字节，所以在强制转换数据时不需要调整字节的内容，直接将后面的截掉就行（比如把int的4字节强制转换成short的2字节时，就直接把int数据存储的前两个字节给short就行，因为其前两个字节刚好就是最低的两个字节，符合转换逻辑）
2. CPU做数值运算时从内存中依顺序依次从低位到高位取数据进行运算，直到最后刷新最高位的符号位，这样的运算方式会更高效

**大端模式优点：**

1. 符号位在所表示的数据的内存的第一个字节中，便于快速判断数据的正负和大小

注意，不同的CPU识别的字节序不同，`x86`系列的CPU采用 **小端模式**，而 `ARM`都可以识别。

**TCP/IP协议规定，网络字节序采用大端模式**  如果是`x86`的CPU，发送数据的时候必须要将自己的主机字节序转换为网络字节序 即大端字节序，接收到的数据再转换为自己的主机字节序，底层会提供转换接口直接调用即可：htons、htonl、ntohs、ntohl等

可以写一个C程序验证大小端

```c
#include<stdio.h>

int main(){
        int i=0x1234;
        char *p = (char*)&i;
        if (*p==0x34){
                printf("小端\n");
        }else{
                printf("大端\n");
        }
}
```

​        

## 参考

- 《编码：隐匿在计算机软硬件背后的语言》
- https://juejin.cn/post/6844904178259591181 （二进制）
- https://liyucang-git.github.io/2019/06/17/彻底弄懂Unicode编码 （编码）

- [幼麟实验室字符串](https://www.bilibili.com/video/BV1hv411x7we)