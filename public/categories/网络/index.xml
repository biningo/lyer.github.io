<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title>网络 - 分类 - lyer's blog</title><link>/categories/%E7%BD%91%E7%BB%9C/</link><description>网络 - 分类 - lyer's blog</description><generator>Hugo -- gohugo.io</generator><language>zh-CN</language><managingEditor>icepan@aliyun.com (lyer)</managingEditor><webMaster>icepan@aliyun.com (lyer)</webMaster><lastBuildDate>Tue, 01 Jun 2021 00:00:00 +0000</lastBuildDate><atom:link href="/categories/%E7%BD%91%E7%BB%9C/" rel="self" type="application/rss+xml"/><item><title>XSS和CSRF攻击</title><link>/2021/06/01/xss%E5%92%8Ccsrf%E6%94%BB%E5%87%BB/</link><pubDate>Tue, 01 Jun 2021 00:00:00 +0000</pubDate><author>作者</author><guid>/2021/06/01/xss%E5%92%8Ccsrf%E6%94%BB%E5%87%BB/</guid><description><![CDATA[XSS攻击 Cross Site Script 跨站脚本攻击，为了不和CSS混淆，所以缩写为XSS
在网页的输入框中最容易被XSS攻击，比如在一个评论框中，用户输入了以下内容
&lt;script&gt;alert(“hello,XSS”)&lt;/script&gt; 那么网页在渲染这段数据的时候就相当于嵌入了一段js脚本代码，以后所有用户访问此网站都会被执行这段代码
上面注入的只是简单的弹窗代码，但是如果注入的是一些恶意的js脚本，那么每个用户访问都会在后台默默的执行注入的恶意js代码
恶意的js代码可以做啥呢
 窃取用户的Cookie，如果Set-Cookie没有设置HttpOnly的话则可以被js代码读取并且通过网络转发给黑客，那么用户的Cookie数据就泄露了 伪造用户，通过js脚本使用用户的Cookie来请求网站，以此假冒用户登入 (利用浏览器的同源策略可以避免) 劫持流量实现恶意跳转，每当用户访问时js代码执行强行跳转劫持用户到另外的站点  预防XSS
  过滤用户的输入
  将用户的输入内容插入特殊符号进行转义
  ​
CSRF攻击 Cross Site Request Forgery 跨站请求伪造攻击
攻击者诱导受害者进入第三方网站，在第三方网站中，向被攻击网站发送跨站请求
利用受害者在被攻击网站已经获取的注册凭证Cookie，绕过后台的用户验证，达到冒充用户对被攻击的网站执行某项操作的目的
下面是一个案例
 小明登入了银行网站A，网站A设置Cookie来作为用户之后请求的Token 小明在登入银行A之后被诱导点击了网站B 网站B向A发送了一个转账请求，浏览器会携带上之前网站A设置的Cookie A收到请求之后就会验证通过，此时小明的钱就被网站B转走了  网站B在受害者不知情的情况下冒充受害者，通过Cookie让网站A执行了网站B定义的操作
由于浏览器有同源策略，因此网站B向网站A发送请求会被浏览器认定为跨域，因此会被浏览器拦截
但是有下面几种情况不会被拦截:
  所有拥有src属性的 &lt;script&gt;、&lt;img&gt;、&lt;iframe&gt; 以及&lt;a&gt;标签等，是不会经过同源策略，因为浏览器认为这些标签肯定是网站主动引用外部资源所加入的的所以不需要规定同源策略，例如baidu.com引用了CDN的jquery
  浏览器为了方便表单的提交，所以 &lt;form&gt; 中填的action 也不会限制同源策略，可以填写任意的URL，一旦用户提交表单那么就会请求URL发生跨域。如果用户在恶意网站里面填写并提交了表单则可能会被CSRF攻击
  如何防止CSRF攻击？
 服务端验证请求，比如验证HTTP请求头的Referer字段 浏览器同源策略，防止跨域请求 加入token，比如我们可以在请求参数后面附加一个token，每次请求都验证一下这个token，因为黑客并不知道这个token，则可以防止CSRF攻击  ​
参考 如何防止XSS攻击？
如何防止CSRF攻击？
安全篇——如何预防CSRF攻击
Cookie 的 SameSite 属性]]></description></item><item><title>同源策略和跨域请求</title><link>/2021/06/01/%E5%90%8C%E6%BA%90%E7%AD%96%E7%95%A5%E5%92%8C%E8%B7%A8%E5%9F%9F%E8%AF%B7%E6%B1%82/</link><pubDate>Tue, 01 Jun 2021 00:00:00 +0000</pubDate><author>作者</author><guid>/2021/06/01/%E5%90%8C%E6%BA%90%E7%AD%96%E7%95%A5%E5%92%8C%E8%B7%A8%E5%9F%9F%E8%AF%B7%E6%B1%82/</guid><description><![CDATA[何为同源，何为跨域 首先需要知道什么是 同源和非同源
同源: 域名、协议、端口 完全一致就是同源头
不同源之间相互访问就叫 跨域访问
google.com www.google.com #域名不一致 不同源 google.com:8080 google.com:9090 #端口不一致 不同源 http://google.com https://google.com #协议不一致 不同源 google.com/b.html google.com/c.html #同源 ​
什么是同源策略 浏览器对于非同源请求做出了如下限制，也就是同源策略
  无法读取非同源的 Cookie、LocalStorage IndexDB等内容
  无法读取和修改非同源的DOM
  无法发送非同源的AJAX，如果发送了非同源请求就会被浏览器拦截
  无法发送非同源的请求
  ​
为什么需要同源策略 如果没有同源策略，那么假如小明在A网站登入了，如果小明在没有注销期间访问了B网站，B网站中携带了js脚本向A网站发起了模拟用户的请求，那么此请求会携带上浏览器保存的Cookie，这样B网站的js脚本就可以模拟小明随意操作了，这就是 CSRF跨站脚本伪造攻击
​
跨域请求 在前后端分离的应用中需要规避这个同源策略，因为这是我们主动发起的跨域请求，自认为是安全的，例如前端地址为abc.com:8080,后端API为abc.com:9090 直接访问API会触发同源策略被浏览器拦截，所以需要想办法跨过去
主要有如下几个跨域请求的方法:
  CORS 跨域资源共享
HTTP设置了跨域专用的请求头，后端API服务器abc.com:9090 告诉浏览器特定URL abc.com:8080的ajax请求可以直接使用，不会激活同源策略
  nginx反向代理
前端通过指定路径 abc.com:8080/api 访问后端请求，nginx配置此前缀的URL反向代理到abc.com:8080
  所有拥有src属性的 &lt;script&gt;、&lt;img&gt;、&lt;iframe&gt; 以及&lt;a&gt;标签等，是不会经过同源策略，因为这些标签肯定是网站主动引用外部资源的所以不需要规定同源策略，例如baidu.com引用了CDN的jquery
所以我通过调用js脚本的方式，从服务器上获取JSON数据绕过同源策略]]></description></item><item><title>HTTP缓存</title><link>/2021/05/31/http%E7%BC%93%E5%AD%98/</link><pubDate>Mon, 31 May 2021 00:00:00 +0000</pubDate><author>作者</author><guid>/2021/05/31/http%E7%BC%93%E5%AD%98/</guid><description><![CDATA[浏览器缓存原理 浏览器会把请求的URL作为key，value就是此次请求对应的响应。每次查找缓存的时候就会到内存或则磁盘去查找key对应的响应信息即可
​
Cache-Control 强缓存 Cache-Control 控制浏览器缓存的时间，注意此头部是通用头部，请求和响应都可以有
如果是服务器响应头部的话则是告诉浏览器此信息可以缓存多久，下面的报文表示可以缓存10s
GET /ping HTTP/1.1 Cache-Control: max-age=10 Content-Length: 4 Content-Type: application/json; charset=utf-8 Date: Tue, 01 Jun 2021 13:23:49 GMT 比如我现在一个重定向到此请求，则下次重定向就不需要再次请求/ping了，直接从缓存里面读取，下面是go后端演示程序
func main() { r := gin.Default() r.GET(&#34;/ping&#34;, func(context *gin.Context) { context.Header(&#34;Cache-Control&#34;, &#34;max-age=10&#34;) context.JSON(200, &#34;OK&#34;) }) r.GET(&#34;/a&#34;, func(context *gin.Context) { context.Header(&#34;Location&#34;, &#34;/ping&#34;) context.Status(302) //临时重定向 不会被浏览器缓存 每次请求都会打到后端 	}) r.GET(&#34;/b&#34;, func(context *gin.Context) { context.Header(&#34;Location&#34;, &#34;/ping&#34;) context.Status(301) //永久重定向 会被浏览器缓存 下次请求此则直接从缓存中读取响应报文 然后直接重定向到/ping 	}) r.Run(&#34;:8080&#34;) } 用户主动刷新、地址栏重新输入、ctrl+f5强制刷新等动作浏览器会自动的在请头中设置Cache-Control的值为max-age=0 或则 no-cache ，表示直接请求服务器而不从缓存中读取，不管缓存是否过期都会请求服务器]]></description></item><item><title>TCP半连接和全连接队列</title><link>/2021/05/27/tcp%E5%8D%8A%E8%BF%9E%E6%8E%A5%E5%92%8C%E5%85%A8%E8%BF%9E%E6%8E%A5%E9%98%9F%E5%88%97/</link><pubDate>Thu, 27 May 2021 00:00:00 +0000</pubDate><author>作者</author><guid>/2021/05/27/tcp%E5%8D%8A%E8%BF%9E%E6%8E%A5%E5%92%8C%E5%85%A8%E8%BF%9E%E6%8E%A5%E9%98%9F%E5%88%97/</guid><description>什么是半连接和全连接队列 操作系统在listen开启监听时就会建立两个队列
半连接 全连接 半连接队列存放的就是一些还没建立TCP连接，并且还在三次握手过程中的客户端连接
全连接队列存放的就是一些已经完全建立TCP连接但是还没被应用层取走的连接，每次应用层调用accept时就会从全连接队列里取一个连接去处理，但是如果队列中没有连接就会阻塞
​
半连接队列 当服务器端在LISTEN状态时能接受其他客户端的TCP建立连接请求，当服务器收到客户端发来的SYN包时就会回复ACK+SYN，此时服务器就进入了 SYN_RECV的状态，这个时候服务器就会将这个连接存放到半连接队列中，并且等待客户端发来应答的ACK
如果在指定时间内客户端没有发第三次握手，则服务器会进行重试直到超过一定次数则会将此连接从半连接队列里面删除
#SYN+ACK重试次数 默认为5 /proc/sys/net/ipv4/tcp_synack_retries ​
如果客户端发来了第三次握手ACK，则会将此连接放入全连接队列等待用户应用去队列里面取
如果半连接队列满了的话，则服务器不会继续接受客户端的连接请求，当其他客户端想要建立TCP连接发送SYN时，服务器就会发送RST报文告诉客户端 &amp;ldquo;连接失败&amp;quot;或则是直接丢弃
​
半连接队列大小 半连接队列大小收到下面几个因素影响
用户层 listen 传入的backlog （用户传入的全连接队列大小） 系统变量 net.ipv4.tcp_max_syn_backlog，默认值为 128 系统变量 net.core.somaxconn，默认值为 128 （Linux配置的全连接队列大小） int listen(int sockfd, int backlog); //第二个参数 /proc/sys/net/ipv4/tcp_max_syn_backlog #1024 /proc/sys/net/core/somaxconn #4096 如果我们想要增加半连接队列的大小，我们就需要同时增加上面三个值，而单单的增加其中的几个则可能无法增加半连接队列的大小
​
全连接队列 当服务器收到客户端发来的第三次握手的时候，服务器就会将这个连接从半连接队里里面转移到全连接队里面并等待应用去全连接队列里取连接进行处理，应用一旦取走该连接就不会保存在队列里了
全连接队列只是用来保存已经建立TCP连接但是还没被用户取走待处理的连接
如果全连接队列满了的话服务器会使用下面两种策略，用户可以在一下文件中配置
/proc/sys/net/ipv4/tcp_abort_on_overflow 0 全连接队列满了则server会丢弃ACK，当作没收到
即使收到了客户端发来的第三次握手ACK也会丢弃当做没收到，则此半连接就无法进入全连接队里，同时server端也会在超时的时候继续发送SYN+ACK，当重试超过指定次数之后全连接队列还是满的则会因为将此半连接删除
1 全连接队列满了则会发送RST包告诉客户端废除这个连接请求
一般配置为0可以有效的增加服务器的并发能力，可能全连接队列只是短暂的满了，之后会被快速取走，则配置为0之后，在后面重试的ACK中还是可以建立连接的
​
全连接队列大小 全连接大小由操作系统配置somaxconn和用户应用配置的backlog两个值确定的</description></item><item><title>TCP协议中的KeepAlive机制</title><link>/2021/05/27/tcp%E5%8D%8F%E8%AE%AE%E4%B8%AD%E7%9A%84keepalive%E6%9C%BA%E5%88%B6/</link><pubDate>Thu, 27 May 2021 00:00:00 +0000</pubDate><author>作者</author><guid>/2021/05/27/tcp%E5%8D%8F%E8%AE%AE%E4%B8%AD%E7%9A%84keepalive%E6%9C%BA%E5%88%B6/</guid><description>HTTP中的keep-alive 在HTTP的头部中，也有一个字段
connection: keep-alive 此字段告诉服务器HTTP会复用这一条TCP连接，当前的HTTP请求完毕之后不会立即断开连接，还可以被另外的HTTP请求复用这条连接，这样就可以减少建立TCP连接的次数
​
TCP的长连接和短连接 TCP连接并没有分为长短连接，长短连接只是在于你如何使用TCP
如果建立TCP连接短暂通讯结束之后立即释放这条连接则此连接就为短连接，比如我HTTP发一次请求就建立一次TCP连接，HTTP响应回来之后就立即断开TCP连接
短连接的缺点就是需要频繁的建立TCP连接，比较耗时，优点就是可以很快的释放TCP连接队列，以便于空出位置建立其他TCP连接
如果建立TCP连接在使用时候不立即断开，如果一直没有请求的话就将这条连接空闲即可，以便与后面如果还要请求通讯的话就不需要建立TCP连接了，直接复用那条已经建立好的TCP连接即可。比如我HTTP请求建立TCP连接，响应结束之后浏览器不会立即释放与服务器的TCP连接，如果下次还有其他请求的话则可以复用之前建立的TCP连接即可，如果一时半会儿还没有请求的话只需要将TCP连接空闲着即可，等下次有请求了就可以继续用这条连接进行传输
长连接的优点就是可以减少建立TCP连接的消耗，复用连接。缺点就是如果很长一段时间都没有数据可发的话就会占用操作系统的TCP全连接队列，如果TCP全连接队列比较紧张的话那么就无法建立其他的TCP连接了
​
TCP的KeepAlive机制 TCP的KeepAlive机制会在指定的间隔时间发送KeepAlive探活包，如果收到了KeepAlive包的ACK则表明对方还在，如果多次发送KeepAlive包都得不到回复则可以认为对方已经挂了，就可以将这个TCP连接从队列里面删除了
KeepAlice主要有如下几个作用:
保活 解决窗口值为0的情况 在空闲的长连接里我们可以通过KeepAlive机制探测对方是否存活，如果收到ACK则表明对方还存活并且还需要复用这条连接
如果多次发送KeepAlive都收不到则说明对方已经挂了或则对方拒绝回复，这样就表明这条长连接可以断开清除了。如果没有KeepAlive机制如果对方挂了则这个连接还会一直保留在服务区占用着TCP全连接队列
还有一种情况就是在接收方的窗口值为0的情况下，那么发送方就不能继续发送数据了，那么即使接收方的窗口扩大了也没有办法告诉发送方，此时就相当于死锁了双方都不会发送数据
所以KeepAlive探测包还可以用于解决窗口值减少为0而造成死锁的情况。当接收方的窗口为0的时候，发送方可以定时的发送KeepAlive包来探测接收方的窗口是否扩大了
​
Linux中KeepAlive相关配置 #7200 每7200s发送KeepAlive包 /proc/sys/net/ipv4/tcp_keepalive_time #75 如果75s内没有收到KeepAlive的ACK则再次发送 /proc/sys/net/ipv4/tcp_keepalive_intvl #9 如果重试9次都没有响应则把此连接删除掉 /proc/sys/net/ipv4/tcp_keepalive_probes ​
KeepAlive能携带数据吗 注意，KeepAlive包的seq也是没有意义的，seq一般和初始化的seq一致，KeepAlive是不携带数据的</description></item><item><title>netcat和socat网络小工具</title><link>/2021/05/19/netcat%E5%92%8Csocat%E7%BD%91%E7%BB%9C%E5%B0%8F%E5%B7%A5%E5%85%B7/</link><pubDate>Wed, 19 May 2021 00:00:00 +0000</pubDate><author>作者</author><guid>/2021/05/19/netcat%E5%92%8Csocat%E7%BD%91%E7%BB%9C%E5%B0%8F%E5%B7%A5%E5%85%B7/</guid><description>netcat网络瑞士军刀 netcat是一个网络小工具，可以用来监听端口，数据回发(简单的echo)，TCP端口扫描，探测网络，网络测速等
echo监听端口和连接端口
#server -l表示监听 nc -l 8000 #监听8000端口 #client nc localhost 8000 #连接本地的8000端口 #然后直接输入数据对方就可以收到了 #监听UDP端口 nc -u -l 8080 #请求UDP端口 nc -u localhost 8080 传输文件
#server nc -l 1234 &amp;gt; filename.out #client nc -N localhost 1234 &amp;lt; filename.in #-N表示如果接受到EOF则断开 端口扫描和检测端口
# -z表示只是检测端口 不需要发送数据 # -v表示显示详细信息 # -w表示指定超时时间s nc -zv host.example.com 20-30 #[20,30] nc -zv icepan.cloud 9000 #端口检测 telnet效果一样 nc -zv -w 5 icepan.cloud 1111 #检测端口设置超时时间为5s 结合pv网络测速（pv用于测量任何操作的数度，可以以管道符来测量）
#server nc -l 8080 &amp;lt; /dev/zero #给这个传输无限多个空白字符串 #client nc icepan.</description></item><item><title>TTL和MSL</title><link>/2021/05/14/ttl%E5%92%8Cmsl/</link><pubDate>Fri, 14 May 2021 00:00:00 +0000</pubDate><author>作者</author><guid>/2021/05/14/ttl%E5%92%8Cmsl/</guid><description>TTL Time To Live 指定了IP包允许跳转(允许通过的最大网段数量)的路由器数量，最大值为255，推荐值为64
TTL在IP数据包中表示
IP数据包每经过一个路由器其值就会-1，一旦TTL=0路由器就会将该IP数据包丢弃，并向IP包的发送者发送 ICMP time exceeded消息
TTL主要就是为了防止IP数据包在网络上出现无限的循环跳转，一旦出现循环跳转的话就会比较浪费网络资源
​
MSL Maximum Segment Lifetime最大报文段生存时间，此时间应该是略大于TTL跳转的时间的，也就是说一旦IP包只要送到对方的机器上，那么此包就一定不会超过MSL，想象一下如果MSL小于TTL那么IP包送到了但是TCP包超时了那么就会比较浪费资源，并且因为TCP包是包含在IP包上的，里面的时间按逻辑上就应该大于等于TTL的
所以只要经过了MSL时间，那么TCP包就肯定已经被传输线路上的路由器给丢弃了
​
参考 TCP/IP</description></item><item><title>TLS(SSL)协议</title><link>/2021/03/16/tlsssl%E5%8D%8F%E8%AE%AE/</link><pubDate>Tue, 16 Mar 2021 00:00:00 +0000</pubDate><author>作者</author><guid>/2021/03/16/tlsssl%E5%8D%8F%E8%AE%AE/</guid><description>什么是TLS协议 因为HTTP传输都是明文传输的，如果被中间人截获，那么报文内容就会被盗取
为了防止HTTP明文传输，于是可以讲HTTP报文和数据整个进行加密然后再将数据传递给下层的TCP层，传递到客户端再进行解密，TLS协议就是解决HTTP报文加密问题的，被TLS协议加密之后的HTTP协议就叫HTTPS HTTP over SSL 使用的是443端口
TLS是SSL的改进版，现在都是使用TLS来替换SSL了，但是延续了老的叫法，所有都叫SSL 这两个其实是同一个意思
TLS现在广泛使用的版本为TLS1.2 TLS1.3
加密算法有对称加密、非对称加密 ，如果将HTTP报文采用非对称加密的话那么带来的CPU运算是非常大的，速度也相对较慢，因为HTTP报文一般数据比较大
所以TLS采用对称加密的方式来加密HTTP报文加快加密解密的速度，但是这里就涉及到如何传递 对称密钥 的问题了，这就是 TLS握手 需要解决的问题
TLS握手的作用:
商定双方使用的非对称加密算法和TLS版本 传输非对称加密算法所需的参数和随机数，随机数的作用是加大解密的难度 传输证书和公钥 (非对称加密算法需要使用公私钥) ​
TLS握手第一阶段 1、Client Hello TCP建立之后浏览器会先发送一个Client Hello 报文给服务器，目的是为了告诉服务器如下内容，重点关注如下内容:
客户端TLS版本 支持的加密套件Cipher Suites 服务器会从中选择一个加密算法 随机字符串Random1 ， 这个随机数和之后的生成对称密钥有关 Session ID 用来恢复会话 SessionTicket 客户端保存的TLS的session信息 2、Server Hello 服务器接受到客户端的Client Hello之后就会检查客户端版本、加密套件等信息，检查通过并且符合服务器的条件则服务器会进行回复，也就是发送Server Hello包
回复内容主要是告诉客户端如下几个重要的内容:
确认SSL/TLS协议版本，如果浏览器不⽀持，则关闭加密通信
从Client Hello中选择一个加密套件，如选择RSA，并且告诉客户端选择了那个加密套件用于后面的加密
随机字符串Random2，此时客户端和服务器都拥有两个随机数 Random1、Random2
初次握手服务器会返回一个Session ID，客户端会保存这个ID，之后再进行握手发送Client Hello的时候就会携带上这个Session ID，服务器就会直接查询Session ID对应的信息比如对称加密的密钥，这样就可以直接复用了就不需要再次生成了，因为生成过程也有一定的消耗</description></item><item><title>WebSocket协议</title><link>/2021/03/16/websocket%E5%8D%8F%E8%AE%AE/</link><pubDate>Tue, 16 Mar 2021 00:00:00 +0000</pubDate><author>作者</author><guid>/2021/03/16/websocket%E5%8D%8F%E8%AE%AE/</guid><description>WebSocket要解决的问题 由于HTTP是请求应答模式，所以如果是聊天室这样的项目的话，那么为了立即获取到信息浏览器就必须进行不断的轮询服务器，不仅效率低下，而且还无法立即获取到数据
于是就有了WebSocket协议，WebSocket是通过HTTP协议进行握手然后再进行通讯的，因为浏览器无法同服务器直接建立TCP连接，所以只能先通过HTTP协议建立一个TCP连接通道，之后再升级协议采用WebSocket协议，这样WebSocket就和HTTP采用相同的端口进行和服务器通讯了
ws://www.chrono.com ws://www.chrono.com:8080/srv wss://www.chrono.com:445/im?user_id=xxx #加密的websocket协议 ​
WebSocket握手 WebSocket握手是通过HTTP协议进行的
首先浏览器请求升级协议
GET /xx HTTP/1.1 Connection: Upgrade Upgrade: websocket Sec-WebSocket-Key: sdadsxxada== Sec-WebSocket-Version: 13 Sec-WebSocket-Key 是一个 Base64的16byte的随机数 用于简单认证，防止误连
然后浏览器返回101响应
HTTP/1.1 101 Switching Protocols Sec-WebSocket-Accept: dsdada Sec-WebSocket-Accept 是把请求头里Sec-WebSocket-Key的值，加上一个专用的 UUID “258EAFA5-E914-47DA-95CA-C5AB0DC85B11”，再计算 SHA-1 摘要，客户端接受到响应之后使用相同的方法计算出摘要然后判断是否相等，相等表示认证成功
握手成功之后传递的就是WebSocket报文了
​
WebSocket报文格式 域 说明 FIN 1bit，是否为信息的最后一帧 RSV 1-3 1bit，备用，默认为0 opcode 4bit，帧类型 1 表示帧内容是纯文本，2 表示帧内容是二进制数据，8 是关闭连接，9 和 10 分别是连接保活的 PING 和 PONG MASK 1bit 掩码，是否用XOR进行简单加密数据。 客户端发送给服务端时，mask必须为1，否则断开连接。 服务端发送给客户端时，mask必须为0，否则断开连接。 payload length 表示帧的长度。它是另一种变长编码，最少 7 位，最多是 7+64 位，一个 WebSocket 帧最大是 2^64 Masking-key 0或32 bit掩码值(Mask为1时才有)，是一个4byte的随机数 Playload data 长度为Payload len的数据，如果有掩码，需要用Masking-Key来异或解密 ​</description></item><item><title>TCP协议</title><link>/2021/03/11/tcp%E5%8D%8F%E8%AE%AE/</link><pubDate>Thu, 11 Mar 2021 00:00:00 +0000</pubDate><author>作者</author><guid>/2021/03/11/tcp%E5%8D%8F%E8%AE%AE/</guid><description>TCP协议 面向连接、可靠的字节流传输协议 全双工 可相互传递字节流 只可用于 一对一通信 ，不能用于多播和组播 TCP 使用校验和，确认和重传机制来保证可靠传输 TCP 使用滑动窗口机制来实现流量控制，通过动态改变窗口的大小进行拥塞控制 TCP使用 (源地址，源端口，目的地址，目的端口)来标识一个连接 ​
TCP报文 源端口和目的端口 端口大小为16位，可见端口范围为:0~2^16 也就是[0~65536]
IP层则用ip地址来标识一台主机，TCP层用端口来标识一个应用，使用(源地址，源端口，目的地址，目的端口)唯一确定一个连接，所以对于IPV4的话单台主机最大的连接数为 2^(32+16+32+16) 个
序号 每个TCP包都有一个序号，编号是为了解决TCP包乱序问题，给每个包编上序号就知道了每个包的顺序，这样就可以完整的拼好所有的TCP包了而不造成乱序，TCP给个字节都有一个序号，序号是整个TCP包数据段的第一个字节的序号，比如现在一个包的起始序号为101，数据长度为500byte ，那么最后一个字节的序号就为600，这个TCP包的序号为第一个字节的序号101 ，所以下一个TCP包的第一个字节的序号应该为601，也就是下一个TCP包的序号为601
如果序号达到最大值2^32，则回卷到0
由于初始的seq号是随机生成的，所以TCP回绕到0之后怎么继续保持字节序呢?怎么判断字节序呢?
回绕之后遇到相同的seq号则可以根据TCP头部携带的时间戳来判断前后
确认号 设置TCP包的确认号是为了告诉对方上一个数据包已经确认收到了，你可以继续发送下一个TCP包了，这个确认号填的就是期望对方发送的下一个TCP包的 序号
比如B收到了A发的序号为101的TCP包，该包长度为500byte，B现在收到了A发的600byte之前的数据，期望A发送下一个序号为601的TCP包，所以确认号为601
A收到B的回复的确认号为601得知B已经收到了A发的600byte之前的数据，现在要发下一个序号为601的TCP包了
首部长度 长度为4位
指出TCP首部的大小，因为TCB首部中有可选择字段，所以每个TCB首部都是不定长的，所以需要指定首部长度，单位是4字节 ，最大为2^4 ，所以首部最大长度为16*4byte=60byte
保留位 6位，保留以后使用，目前全部置0
五大标志位 6位
标志 含义 URG 紧急位，为1的话则表示这是个紧急的TCP包，应该放到发送队列的最前面去立即发送 ACK ACK=1表示确认号有效，ACK=0表示确认号无效，TCP连接建立成功后所有的传输报文必须把ACK置为1 PSH 很少用到，一般为0 RST 复位 RST=1 表示TCP连接出错，必须释放连接重新建立 SYN 同步 SYN=1表示这是一个请求建立连接或接受建立连接请求报文 SYN=1 ACK=0表示这是一个建立连接请求，SYN=1 ACK=1表示这是一个应答建立连接请求的TCP报文，详情请参考TCP三次握手 FIN 用来释放连接， FIN=1 表示数据已经发送完毕并且请求释放TCP连接 窗口大小 TCP使用 滑动窗口 来实现拥塞控制和流量控制，详情请见下文，比如B响应给A的报文中窗口字段的大小为1000 ，确认号为101 目的就是为了告诉A可以发送101开始的数据包了，缓存空间大小为1000byte，也就是还可以接受101~1101字节范围的数据包</description></item></channel></rss>